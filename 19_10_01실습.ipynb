{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "19-10-01실습.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jae-gyeong/marchine_learning_start/blob/master/19_10_01%EC%8B%A4%EC%8A%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qESZHRSR_f0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tensorflow import\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30VODPNiSMkj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 학습할 데이터 지정\n",
        "x_data = [1,2,3,4,5]\n",
        "y_data = [10,20,30,40,50]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MS2HSChsSOLK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 가중치와 바이어스를 -1~1사이의 균등분포 값을 갖는 무작위 값으로 설정\n",
        "W = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
        "b = tf.Variable(tf.random_uniform([1], -1.0, 1.0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75Nsjr-FSZGa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7d3144ce-5bbc-4c8c-bb2c-bb77467fdc47"
      },
      "source": [
        "print(W)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tf.Variable 'Variable:0' shape=(1,) dtype=float32_ref>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAbj7eNtSpa6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2a237e95-504e-43b8-9eaa-23a7a631b0b4"
      },
      "source": [
        "print(b)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tf.Variable 'Variable_1:0' shape=(1,) dtype=float32_ref>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqZs44csSqKZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "67bdaaf5-1ac4-4b9c-9c50-7eb786f589ef"
      },
      "source": [
        "# 플레이스 홀더 설정(값을 넣을 빈 공간을 만든다. 실수가 들어갈 수 있고, 그 공간의 이름을 X, Y로 한다\n",
        "X = tf.placeholder(tf.float32, name='X')\n",
        "Y = tf.placeholder(tf.float32, name='Y')\n",
        "print(X)\n",
        "print(Y)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"X:0\", dtype=float32)\n",
            "Tensor(\"Y:0\", dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5YxtXIsStgn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# score 함수 만들기\n",
        "# 선형관계의 수식을 작성.\n",
        "# W : 가중치(Weight), b : 편향(bias)\n",
        "score = W*X+b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6cQ2IBkS52q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "faea785e-487b-4094-ddd0-0f0a8a1bd693"
      },
      "source": [
        "# 손실함수(loss function) 만들기, simple한 loss function 사용.\n",
        "# score에서 실제 Y값을 뺀 것의 제곱의 평균을 loss로 사용하겠다.\n",
        "loss = tf.reduce_mean(tf.square(score - Y))\n",
        "loss"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'Mean:0' shape=() dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJIybrwCS-8H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "db4c05b0-2556-4a1f-a83c-9979804fc458"
      },
      "source": [
        "# 최적화 함수(경사하강법)\n",
        "# GradientDescentOptimizer 객체 만들기\n",
        "# learning_rate는 학습 속도로 0.01로 주겠다.\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
        "# GradientDescentOptimizer에 최적화 방법을 loss가 최소가 되게하는 minimize() 메서드 사용하기\n",
        "train_op = optimizer.minimize(loss)\n",
        "train_op"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Operation 'GradientDescent' type=NoOp>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsvFty-YS_Co",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0d0d67d4-36f6-4541-d91a-9d16ecc298dc"
      },
      "source": [
        "# with tf.Session() as sess:\n",
        "#  sess.run(tf.global_variables_initializer())\n",
        "\n",
        "#  for step in range(100):\n",
        "#    _, _val = sess.run([train_op, cost], feed_dict={X:x_data, Y:y_data})\n",
        "#    print(step, \"Cost = %-10.5f\" % cost_val, \"W = %10.6f\" % sess.run(W), \"B = %10.6f \" % sess.run(b)\n",
        "      \n",
        "      \n",
        "# # 세션을 with구문으로 열자.\n",
        "with tf.Session() as sess:\n",
        "# # 값을 초기화 하는 함수를 먼저 실행한다.\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "# # training data로 101번 학습 시키기\n",
        "# # 학습시 경사하강법을 최적화 함수로 사용하고, loss 값을 최소가 되게 만든다.\n",
        "# # 데이터는 플레이스홀더 X에는 x_data를 넣어주고\n",
        "# # 플레이스 홀더 Y에는 y_data를 넣어준다.\n",
        "# # 값을 2개 반환 받게 되는데 loss값만 loss_val 변수로 저장하자.\n",
        "  for step in range(100):\n",
        "    _, loss_val = sess.run([train_op, loss], feed_dict={X:x_data, Y:y_data})\n",
        "    print(step, 'Loss = %-10.5f' % loss_val, 'W = %10.6f' % sess.run(W), 'B = %10.6f' % sess.run(b))# 횟수, cost, W, B 찍어보기\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Loss = 1299.38086 W =   1.505427 B =   0.714587\n",
            "1 Loss = 757.82538  W =   3.331358 B =   1.209970\n",
            "2 Loss = 442.22949  W =   4.725861 B =   1.585889\n",
            "3 Loss = 258.31183  W =   5.791018 B =   1.870619\n",
            "4 Loss = 151.12959  W =   6.604757 B =   2.085746\n",
            "5 Loss = 88.66505   W =   7.226566 B =   2.247745\n",
            "6 Loss = 52.25983   W =   7.701857 B =   2.369196\n",
            "7 Loss = 31.04065   W =   8.065296 B =   2.459701\n",
            "8 Loss = 18.67124   W =   8.343349 B =   2.526589\n",
            "9 Loss = 11.45903   W =   8.556216 B =   2.575456\n",
            "10 Loss = 7.25219    W =   8.719321 B =   2.610574\n",
            "11 Loss = 4.79678    W =   8.844436 B =   2.635204\n",
            "12 Loss = 3.36203    W =   8.940548 B =   2.651833\n",
            "13 Loss = 2.52210    W =   9.014518 B =   2.662364\n",
            "14 Loss = 2.02883    W =   9.071582 B =   2.668245\n",
            "15 Loss = 1.73761    W =   9.115739 B =   2.670585\n",
            "16 Loss = 1.56415    W =   9.150042 B =   2.670229\n",
            "17 Loss = 1.45934    W =   9.176819 B =   2.667822\n",
            "18 Loss = 1.39457    W =   9.197849 B =   2.663857\n",
            "19 Loss = 1.35315    W =   9.214491 B =   2.658709\n",
            "20 Loss = 1.32536    W =   9.227780 B =   2.652665\n",
            "21 Loss = 1.30555    W =   9.238509 B =   2.645945\n",
            "22 Loss = 1.29040    W =   9.247280 B =   2.638715\n",
            "23 Loss = 1.27800    W =   9.254556 B =   2.631104\n",
            "24 Loss = 1.26722    W =   9.260687 B =   2.623209\n",
            "25 Loss = 1.25741    W =   9.265944 B =   2.615103\n",
            "26 Loss = 1.24819    W =   9.270530 B =   2.606845\n",
            "27 Loss = 1.23934    W =   9.274603 B =   2.598476\n",
            "28 Loss = 1.23073    W =   9.278281 B =   2.590030\n",
            "29 Loss = 1.22227    W =   9.281657 B =   2.581533\n",
            "30 Loss = 1.21394    W =   9.284801 B =   2.573003\n",
            "31 Loss = 1.20570    W =   9.287765 B =   2.564455\n",
            "32 Loss = 1.19753    W =   9.290589 B =   2.555900\n",
            "33 Loss = 1.18943    W =   9.293305 B =   2.547347\n",
            "34 Loss = 1.18139    W =   9.295938 B =   2.538801\n",
            "35 Loss = 1.17341    W =   9.298503 B =   2.530269\n",
            "36 Loss = 1.16548    W =   9.301016 B =   2.521754\n",
            "37 Loss = 1.15761    W =   9.303487 B =   2.513258\n",
            "38 Loss = 1.14980    W =   9.305924 B =   2.504783\n",
            "39 Loss = 1.14204    W =   9.308334 B =   2.496332\n",
            "40 Loss = 1.13433    W =   9.310721 B =   2.487905\n",
            "41 Loss = 1.12667    W =   9.313088 B =   2.479504\n",
            "42 Loss = 1.11906    W =   9.315439 B =   2.471128\n",
            "43 Loss = 1.11151    W =   9.317775 B =   2.462780\n",
            "44 Loss = 1.10400    W =   9.320098 B =   2.454458\n",
            "45 Loss = 1.09655    W =   9.322409 B =   2.446162\n",
            "46 Loss = 1.08915    W =   9.324709 B =   2.437895\n",
            "47 Loss = 1.08180    W =   9.327000 B =   2.429654\n",
            "48 Loss = 1.07449    W =   9.329281 B =   2.421441\n",
            "49 Loss = 1.06724    W =   9.331553 B =   2.413255\n",
            "50 Loss = 1.06004    W =   9.333816 B =   2.405097\n",
            "51 Loss = 1.05288    W =   9.336070 B =   2.396966\n",
            "52 Loss = 1.04577    W =   9.338317 B =   2.388863\n",
            "53 Loss = 1.03871    W =   9.340555 B =   2.380787\n",
            "54 Loss = 1.03170    W =   9.342786 B =   2.372738\n",
            "55 Loss = 1.02474    W =   9.345009 B =   2.364716\n",
            "56 Loss = 1.01782    W =   9.347224 B =   2.356721\n",
            "57 Loss = 1.01095    W =   9.349432 B =   2.348753\n",
            "58 Loss = 1.00412    W =   9.351632 B =   2.340812\n",
            "59 Loss = 0.99735    W =   9.353825 B =   2.332898\n",
            "60 Loss = 0.99061    W =   9.356009 B =   2.325011\n",
            "61 Loss = 0.98393    W =   9.358187 B =   2.317150\n",
            "62 Loss = 0.97729    W =   9.360356 B =   2.309315\n",
            "63 Loss = 0.97069    W =   9.362519 B =   2.301508\n",
            "64 Loss = 0.96414    W =   9.364675 B =   2.293726\n",
            "65 Loss = 0.95763    W =   9.366822 B =   2.285971\n",
            "66 Loss = 0.95116    W =   9.368963 B =   2.278243\n",
            "67 Loss = 0.94474    W =   9.371097 B =   2.270540\n",
            "68 Loss = 0.93836    W =   9.373223 B =   2.262863\n",
            "69 Loss = 0.93203    W =   9.375342 B =   2.255213\n",
            "70 Loss = 0.92574    W =   9.377454 B =   2.247588\n",
            "71 Loss = 0.91949    W =   9.379559 B =   2.239989\n",
            "72 Loss = 0.91328    W =   9.381657 B =   2.232416\n",
            "73 Loss = 0.90712    W =   9.383747 B =   2.224868\n",
            "74 Loss = 0.90099    W =   9.385831 B =   2.217346\n",
            "75 Loss = 0.89491    W =   9.387907 B =   2.209849\n",
            "76 Loss = 0.88887    W =   9.389977 B =   2.202378\n",
            "77 Loss = 0.88287    W =   9.392039 B =   2.194932\n",
            "78 Loss = 0.87691    W =   9.394094 B =   2.187511\n",
            "79 Loss = 0.87099    W =   9.396143 B =   2.180115\n",
            "80 Loss = 0.86511    W =   9.398185 B =   2.172744\n",
            "81 Loss = 0.85927    W =   9.400220 B =   2.165398\n",
            "82 Loss = 0.85347    W =   9.402247 B =   2.158077\n",
            "83 Loss = 0.84771    W =   9.404268 B =   2.150780\n",
            "84 Loss = 0.84199    W =   9.406282 B =   2.143509\n",
            "85 Loss = 0.83630    W =   9.408290 B =   2.136261\n",
            "86 Loss = 0.83066    W =   9.410291 B =   2.129039\n",
            "87 Loss = 0.82505    W =   9.412285 B =   2.121840\n",
            "88 Loss = 0.81948    W =   9.414271 B =   2.114666\n",
            "89 Loss = 0.81395    W =   9.416252 B =   2.107517\n",
            "90 Loss = 0.80845    W =   9.418225 B =   2.100391\n",
            "91 Loss = 0.80300    W =   9.420193 B =   2.093290\n",
            "92 Loss = 0.79758    W =   9.422153 B =   2.086213\n",
            "93 Loss = 0.79219    W =   9.424107 B =   2.079159\n",
            "94 Loss = 0.78684    W =   9.426054 B =   2.072130\n",
            "95 Loss = 0.78153    W =   9.427995 B =   2.065124\n",
            "96 Loss = 0.77626    W =   9.429929 B =   2.058142\n",
            "97 Loss = 0.77102    W =   9.431856 B =   2.051183\n",
            "98 Loss = 0.76581    W =   9.433777 B =   2.044248\n",
            "99 Loss = 0.76064    W =   9.435691 B =   2.037337\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrcBNjvDTA3f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "95c1c9de-7dd7-4c85-9dc6-7cec83cfd1c8"
      },
      "source": [
        "# 세션을 with구문으로 열자.\n",
        "with tf.Session() as sess:\n",
        "# 값을 초기화 하는 함수를 먼저 실행한다.\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "# 0~1000 까지 1001번 학습시킨다.\n",
        "# 학습시 경사하강법을 최적화 함수로 사용하고, loss 값을 최소가 되게 만든다.\n",
        "# 데이터는 플레이스홀더 X에는 x_data를 넣어주고\n",
        "# 플레이스 홀더 Y에는 y_data를 넣어준다.\n",
        "# 값을 2개 반환 받게 되는데 loss값만 loss_val 변수로 저장하자.\n",
        "  for step in range(1001):\n",
        "    _, loss_val = sess.run([train_op, loss], feed_dict = {X:x_data, Y:y_data})\n",
        "# 10번마다 횟수, loss값, W값, b값을 확인해보자.\n",
        "    if step%10 ==0:\n",
        "      print(step, loss_val, sess.run(W), sess.run(b))\n",
        "print('Y = {Weight} * X + {Bias}'.format(Weight = sess.run(W), Bias = sess.run(b)))\n",
        "# score 함수에 x값으로 5를 넣어 예측되는 Y값을 보자. X라는 플레이스홀더를 이용하자.\n",
        "print('X:5, Y:', sess.run(hypothesis, feed_dict={X:2.5}))\n",
        "# score 함수에 x값으로 2.5를 넣어 예측되는 Y값을 보자. X라는 플레이스홀더를 이용하자.\n",
        "print('X:2.5, Y:', sess.run(hypothesis, feed_dict={X:2.5}))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 1113.6367 [2.318436] [-0.0042117]\n",
            "10 5.69289 [8.9923935] [1.773657]\n",
            "20 0.64515287 [9.457292] [1.83407]\n",
            "30 0.5817865 [9.504353] [1.7810249]\n",
            "40 0.5435892 [9.522806] [1.7222565]\n",
            "50 0.5079896 [9.538827] [1.664942]\n",
            "60 0.47471994 [9.554193] [1.6095026]\n",
            "70 0.4436306 [9.569038] [1.5559065]\n",
            "80 0.4145766 [9.583389] [1.5040952]\n",
            "90 0.3874262 [9.597263] [1.4540094]\n",
            "100 0.3620542 [9.610674] [1.405591]\n",
            "110 0.3383421 [9.623638] [1.3587849]\n",
            "120 0.31618398 [9.636171] [1.3135376]\n",
            "130 0.29547668 [9.648286] [1.2697972]\n",
            "140 0.27612638 [9.659998] [1.2275137]\n",
            "150 0.25804305 [9.671319] [1.186638]\n",
            "160 0.24114308 [9.682265] [1.1471232]\n",
            "170 0.2253507 [9.692846] [1.1089242]\n",
            "180 0.21059248 [9.7030735] [1.071997]\n",
            "190 0.19680044 [9.712962] [1.0362998]\n",
            "200 0.18391179 [9.72252] [1.0017911]\n",
            "210 0.17186709 [9.73176] [0.9684318]\n",
            "220 0.16061138 [9.740692] [0.93618315]\n",
            "230 0.15009315 [9.749328] [0.9050086]\n",
            "240 0.14026304 [9.757676] [0.87487155]\n",
            "250 0.13107732 [9.765744] [0.845738]\n",
            "260 0.12249281 [9.773545] [0.81757504]\n",
            "270 0.1144709 [9.781086] [0.7903498]\n",
            "280 0.10697329 [9.788376] [0.76403123]\n",
            "290 0.09996733 [9.795423] [0.7385889]\n",
            "300 0.09342103 [9.802236] [0.71399415]\n",
            "310 0.08730265 [9.808821] [0.69021815]\n",
            "320 0.081585154 [9.8151865] [0.66723406]\n",
            "330 0.07624171 [9.821341] [0.6450153]\n",
            "340 0.07124891 [9.82729] [0.62353677]\n",
            "350 0.06658333 [9.833041] [0.6027733]\n",
            "360 0.06222222 [9.838601] [0.5827011]\n",
            "370 0.058147557 [9.843976] [0.5632971]\n",
            "380 0.05433923 [9.849172] [0.54453933]\n",
            "390 0.050780796 [9.854194] [0.5264063]\n",
            "400 0.047454823 [9.859049] [0.5088771]\n",
            "410 0.04434716 [9.863743] [0.49193168]\n",
            "420 0.041442562 [9.86828] [0.47555047]\n",
            "430 0.03872876 [9.872666] [0.45971468]\n",
            "440 0.036192194 [9.876906] [0.4444062]\n",
            "450 0.033822138 [9.881005] [0.42960772]\n",
            "460 0.031606995 [9.884968] [0.41530198]\n",
            "470 0.029536981 [9.888799] [0.40147263]\n",
            "480 0.027602721 [9.892502] [0.38810346]\n",
            "490 0.0257947 [9.896082] [0.37517947]\n",
            "500 0.024105439 [9.899542] [0.36268598]\n",
            "510 0.022526849 [9.902886] [0.35060874]\n",
            "520 0.021051744 [9.90612] [0.33893386]\n",
            "530 0.01967286 [9.909246] [0.32764763]\n",
            "540 0.018384634 [9.912268] [0.31673723]\n",
            "550 0.017180761 [9.915191] [0.30619034]\n",
            "560 0.016055536 [9.9180155] [0.29599398]\n",
            "570 0.015003609 [9.920746] [0.286137]\n",
            "580 0.014021116 [9.923384] [0.2766083]\n",
            "590 0.013103083 [9.925936] [0.26739705]\n",
            "600 0.012244853 [9.928402] [0.25849268]\n",
            "610 0.011442912 [9.930786] [0.24988484]\n",
            "620 0.010693481 [9.933091] [0.24156354]\n",
            "630 0.0099931825 [9.935319] [0.23351942]\n",
            "640 0.009338704 [9.937472] [0.22574317]\n",
            "650 0.008726969 [9.939555] [0.21822585]\n",
            "660 0.00815555 [9.941568] [0.21095884]\n",
            "670 0.0076215207 [9.943514] [0.2039339]\n",
            "680 0.007122261 [9.9453945] [0.19714291]\n",
            "690 0.006655894 [9.947213] [0.19057792]\n",
            "700 0.006219837 [9.948971] [0.18423186]\n",
            "710 0.005812598 [9.95067] [0.17809677]\n",
            "720 0.0054320227 [9.952312] [0.17216629]\n",
            "730 0.005076261 [9.953901] [0.16643308]\n",
            "740 0.0047436818 [9.955436] [0.16089073]\n",
            "750 0.004433154 [9.95692] [0.15553318]\n",
            "760 0.00414268 [9.958355] [0.15035386]\n",
            "770 0.0038713322 [9.959742] [0.14534685]\n",
            "780 0.003617876 [9.9610815] [0.14050667]\n",
            "790 0.0033809175 [9.9623785] [0.1358277]\n",
            "800 0.003159494 [9.963631] [0.1313046]\n",
            "810 0.0029526132 [9.964842] [0.12693197]\n",
            "820 0.0027591526 [9.966013] [0.12270504]\n",
            "830 0.002578423 [9.967145] [0.11861867]\n",
            "840 0.002409532 [9.968239] [0.11466854]\n",
            "850 0.0022517736 [9.969296] [0.11085001]\n",
            "860 0.0021042908 [9.97032] [0.10715839]\n",
            "870 0.0019664105 [9.971307] [0.10358985]\n",
            "880 0.0018377422 [9.972262] [0.10014062]\n",
            "890 0.0017174024 [9.973186] [0.09680621]\n",
            "900 0.0016049158 [9.974079] [0.0935827]\n",
            "910 0.0014997559 [9.974942] [0.09046628]\n",
            "920 0.0014016218 [9.975777] [0.08745398]\n",
            "930 0.0013097858 [9.9765835] [0.08454161]\n",
            "940 0.0012239793 [9.977363] [0.08172635]\n",
            "950 0.0011438422 [9.978117] [0.07900521]\n",
            "960 0.0010689131 [9.978846] [0.07637453]\n",
            "970 0.0009989215 [9.97955] [0.07383128]\n",
            "980 0.0009335571 [9.980231] [0.07137266]\n",
            "990 0.00087237655 [9.980888] [0.06899607]\n",
            "1000 0.0008152714 [9.981525] [0.06669874]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-bd4c19c976db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Y = {Weight} * X + {Bias}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWeight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;31m# score 함수에 x값으로 5를 넣어 예측되는 Y값을 보자. X라는 플레이스홀더를 이용하자.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'X:5, Y:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhypothesis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2.5\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1094\u001b[0m     \u001b[0;31m# Check session.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Attempted to use a closed Session.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m       raise RuntimeError('The Session graph is empty.  Add operations to the '\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Attempted to use a closed Session."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMqJPPGeTA6g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}